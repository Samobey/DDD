{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81288b43",
   "metadata": {},
   "source": [
    "# Long-Term Episodic Memory with LangGraph\n",
    "\n",
    "This notebook demonstrates how to implement long-term episodic memory using embeddings and vector search.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Episodic memory**: Stores specific events, experiences, and interactions with temporal context\n",
    "- **Episodes**: Complete narratives of what happened, when, and the outcome\n",
    "- **Time-aware retrieval**: Retrieve past events relevant to current context\n",
    "- **Sequential memory**: Preserves the order and relationship between events\n",
    "- **Contextual recall**: Access rich details about specific moments in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86bff6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"langgraph\",\n",
    "    \"langchain\",\n",
    "    \"langchain-openai\",\n",
    "    \"langchain-chroma\",\n",
    "    \"python-dotenv\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "\n",
    "print(\"âœ“ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dd4d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ OpenAI API key loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Verify API key\n",
    "api_key = \" \"\n",
    "if not api_key:\n",
    "    print(\"âš ï¸  Warning: OPENAI_API_KEY not found. Please set it in your .env file\")\n",
    "else:\n",
    "    print(\"âœ“ OpenAI API key loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1376c42",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Embeddings and Vector Store\n",
    "\n",
    "Setup the episodic memory system with embeddings and a vector database for storing episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b3121db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Embeddings and vector store initialized\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize embeddings\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=api_key)\n",
    "    \n",
    "    # Initialize vector store for episodes\n",
    "    episode_store = Chroma(\n",
    "        collection_name=\"episodic_memory\",\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "    \n",
    "    print(\"âœ“ Embeddings and vector store initialized\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error initializing embeddings: {e}\")\n",
    "    print(\"Make sure OPENAI_API_KEY is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde81cb",
   "metadata": {},
   "source": [
    "## Step 2: Define the Agent State\n",
    "\n",
    "The state includes:\n",
    "- `messages`: Current conversation\n",
    "- `episodes`: Past events and experiences with temporal context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f5371cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent state defined with short-term and episodic memory\n"
     ]
    }
   ],
   "source": [
    "def add_messages(left: list[BaseMessage], right: list[BaseMessage]) -> list[BaseMessage]:\n",
    "    \"\"\"Append messages to existing messages.\"\"\"\n",
    "    return left + right\n",
    "\n",
    "def add_episodes(left: list[str], right: list[str]) -> list[str]:\n",
    "    \"\"\"Append episodes to existing episodes.\"\"\"\n",
    "    return left + right\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    episodes: Annotated[list[str], add_episodes]\n",
    "\n",
    "print(\"âœ“ Agent state defined with short-term and episodic memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff1d61",
   "metadata": {},
   "source": [
    "## Step 3: Create Agent Nodes\n",
    "\n",
    "1. **extract_episode**: Extract and record specific events with temporal context\n",
    "2. **retrieve_episodes**: Find relevant past experiences\n",
    "3. **agent**: Respond with episode context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d1c2218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent nodes created successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, openai_api_key=api_key)\n",
    "    \n",
    "    def is_valid_episode(text: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if extracted text is a real episode, not meta-commentary.\n",
    "        \"\"\"\n",
    "        # Filter out meta-responses\n",
    "        meta_phrases = [\n",
    "            \"no further episodes\",\n",
    "            \"no episodes to extract\",\n",
    "            \"it appears that\",\n",
    "            \"does not contain\",\n",
    "            \"if there were\",\n",
    "            \"if you have\",\n",
    "            \"please provide\",\n",
    "            \"cannot create\",\n",
    "        ]\n",
    "        \n",
    "        lower_text = text.lower()\n",
    "        if any(phrase in lower_text for phrase in meta_phrases):\n",
    "            return False\n",
    "        \n",
    "        # Must have some actual event description\n",
    "        event_indicators = [\"happened\", \"attended\", \"met\", \"experience\", \"meeting\", \"conference\", \"event\"]\n",
    "        return any(indicator in lower_text for indicator in event_indicators)\n",
    "    \n",
    "    def extract_episode(state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        Extract important episodes (events) from the latest user message.\n",
    "        Store them with temporal context in the vector store.\n",
    "        \"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        \n",
    "        # Get the last user message\n",
    "        last_user_msg = None\n",
    "        for msg in reversed(messages):\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                last_user_msg = msg.content\n",
    "                break\n",
    "        \n",
    "        if not last_user_msg:\n",
    "            return {}\n",
    "        \n",
    "        print(\"ğŸ“ Extracting episodes from message...\")\n",
    "        \n",
    "        # Use LLM to extract events with temporal context\n",
    "        extraction_prompt = f\"\"\"Extract ONLY one main episode (event/experience) from this message if it contains a specific event.\n",
    "\n",
    "Message: {last_user_msg}\n",
    "\n",
    "For the episode, include:\n",
    "- What happened (the event or experience)\n",
    "- When it happened (relative time: today, last week, last month, recently, etc.)\n",
    "- Who was involved (people, organizations, etc.)\n",
    "- The outcome or result\n",
    "\n",
    "Format as a single clear narrative.\n",
    "If there is NO specific event or experience mentioned, respond with: \"No episodes to extract.\"\n",
    "\"\"\"\n",
    "        \n",
    "        episodes_response = llm.invoke(extraction_prompt)\n",
    "        episodes_text = episodes_response.content\n",
    "        \n",
    "        # Store episode in vector store\n",
    "        if episodes_text.strip() and \"no episodes\" not in episodes_text.lower():\n",
    "            # Split by double newline but filter carefully\n",
    "            episodes = [e.strip() for e in episodes_text.split(\"\\n\\n\") if e.strip() and len(e.strip()) > 30]\n",
    "            \n",
    "            # Filter out meta-responses\n",
    "            episodes = [ep for ep in episodes if is_valid_episode(ep)]\n",
    "            \n",
    "            if episodes:\n",
    "                # Add timestamp to episodes for context\n",
    "                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                timestamped_episodes = [\n",
    "                    f\"[Timestamp: {timestamp}]\\n{ep}\" \n",
    "                    for ep in episodes\n",
    "                ]\n",
    "                print(f\"ğŸ’¾ Storing {len(episodes)} episode(s):\\n\")\n",
    "                for i, ep in enumerate(timestamped_episodes, 1):\n",
    "                    print(f\"   Episode {i}:\")\n",
    "                    print(f\"   â° {ep}\")\n",
    "                    print()\n",
    "                episode_store.add_texts(timestamped_episodes)\n",
    "                return {\"episodes\": episodes}\n",
    "        \n",
    "        print(\"âŠ˜ No episodes extracted from this message\")\n",
    "        return {}\n",
    "    \n",
    "    def retrieve_episodes(state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        Retrieve relevant episodes from episodic memory based on current context.\n",
    "        \"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        \n",
    "        # Get the last message\n",
    "        last_msg = messages[-1].content if messages else \"\"\n",
    "        \n",
    "        if not last_msg or len(episode_store.get()[\"ids\"]) == 0:\n",
    "            return {}\n",
    "        \n",
    "        print(\"ğŸ” Retrieving relevant episodes from memory...\")\n",
    "        \n",
    "        # Search for relevant episodes\n",
    "        results = episode_store.similarity_search(last_msg, k=3)\n",
    "        \n",
    "        if results:\n",
    "            # Filter out meta-commentary from retrieved results\n",
    "            valid_results = [doc for doc in results if is_valid_episode(doc.page_content)]\n",
    "            \n",
    "            if valid_results:\n",
    "                print(f\"âœ“ Found {len(valid_results)} relevant episode(s):\\n\")\n",
    "                for i, doc in enumerate(valid_results, 1):\n",
    "                    print(f\"   Retrieved Episode {i}:\")\n",
    "                    print(f\"   ğŸ“– {doc.page_content}\")\n",
    "                    print()\n",
    "                retrieved_episodes = \"\\n\".join([doc.page_content for doc in valid_results])\n",
    "                return {\"episodes\": [f\"[Past experiences]\\n{retrieved_episodes}\"]}\n",
    "            else:\n",
    "                print(\"âŠ˜ No relevant episodes found (only metadata)\")\n",
    "                return {}\n",
    "        \n",
    "        print(\"âŠ˜ No relevant episodes found\")\n",
    "        return {}\n",
    "    \n",
    "    def agent(state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        Agent that processes conversation with episodic memory context.\n",
    "        \"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        episodes = state.get(\"episodes\", [])\n",
    "        \n",
    "        # Build context from episodes\n",
    "        context = \"\"\n",
    "        if episodes:\n",
    "            context = f\"\\nRelevant past experiences:\\n\" + \"\\n\".join(episodes)\n",
    "        \n",
    "        # Prepare system message with episode context\n",
    "        system_msg = f\"\"\"You are a helpful assistant with access to long-term episodic memory.\n",
    "You remember specific events and experiences from past interactions.\n",
    "        \n",
    "{context}\n",
    "\n",
    "Use the past experiences to provide contextual and personalized responses.\"\"\"\n",
    "        \n",
    "        # Call LLM with full context\n",
    "        response = llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            *messages\n",
    "        ])\n",
    "        \n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    print(\"âœ“ Agent nodes created successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating agent nodes: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ea59b",
   "metadata": {},
   "source": [
    "## Step 4: Build the Graph\n",
    "\n",
    "The workflow:\n",
    "1. Extract episodes from user message\n",
    "2. Retrieve relevant past experiences\n",
    "3. Agent responds with episodic context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d473851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Graph compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"extract_episode\", extract_episode)\n",
    "graph_builder.add_node(\"retrieve_episodes\", retrieve_episodes)\n",
    "graph_builder.add_node(\"agent\", agent)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"extract_episode\")\n",
    "graph_builder.add_edge(\"extract_episode\", \"retrieve_episodes\")\n",
    "graph_builder.add_edge(\"retrieve_episodes\", \"agent\")\n",
    "graph_builder.add_edge(\"agent\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"âœ“ Graph compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f88bce",
   "metadata": {},
   "source": [
    "## Step 5: Run a Multi-Turn Conversation Demo\n",
    "\n",
    "Demonstrate how episodic memory stores and recalls specific experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c8c05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸  Clearing previous episodes for a fresh start...\n",
      "âœ“ Cleared 0 old episodes\n",
      "\n",
      "============================================================\n",
      "LONG-TERM EPISODIC MEMORY DEMONSTRATION\n",
      "============================================================\n",
      "\n",
      "Turn 1: User Input\n",
      ">> Last month I attended a AI conference in Berlin where I met amazing people working on LLMs.\n",
      "\n",
      "ğŸ“ Extracting episodes from message...\n",
      "ğŸ’¾ Storing 1 episode(s):\n",
      "\n",
      "   Episode 1:\n",
      "   â° [Timestamp: 2025-12-11 22:05:18]\n",
      "Last month, I attended an AI conference in Berlin where I met amazing people working on LLMs. The event allowed me to network with professionals in the field, enhancing my understanding of language models and their applications.\n",
      "\n",
      "ğŸ” Retrieving relevant episodes from memory...\n",
      "âœ“ Found 1 relevant episode(s):\n",
      "\n",
      "   Retrieved Episode 1:\n",
      "   ğŸ“– [Timestamp: 2025-12-11 22:05:18]\n",
      "Last month, I attended an AI conference in Berlin where I met amazing people working on LLMs. The event allowed me to network with professionals in the field, enhancing my understanding of language models and their applications.\n",
      "\n",
      "Turn 1: Agent Response\n",
      "<< That sounds like a fantastic experience! It seems like you had a great opportunity to connect with professionals in the field of language models. Did you come away with any new insights or ideas from the conference that youâ€™re excited to explore further?\n",
      "\n",
      "ğŸ“š Episodes stored in memory: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "Turn 2: User Input\n",
      ">> Tell me about my recent experiences.\n",
      "\n",
      "ğŸ“ Extracting episodes from message...\n",
      "âŠ˜ No episodes extracted from this message\n",
      "ğŸ” Retrieving relevant episodes from memory...\n",
      "âœ“ Found 1 relevant episode(s):\n",
      "\n",
      "   Retrieved Episode 1:\n",
      "   ğŸ“– [Timestamp: 2025-12-11 22:05:18]\n",
      "Last month, I attended an AI conference in Berlin where I met amazing people working on LLMs. The event allowed me to network with professionals in the field, enhancing my understanding of language models and their applications.\n",
      "\n",
      "Turn 2: Agent Response\n",
      "<< Recently, you attended an AI conference in Berlin where you had the chance to meet incredible people working on language models (LLMs). This event was a great opportunity for networking and deepening your understanding of LLMs and their applications. It sounds like it was a valuable experience for you! Is there anything specific from the conference that stood out to you or that you would like to discuss further?\n",
      "\n",
      "ğŸ“š Episodes stored in memory: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "Turn 3: User Input\n",
      ">> Yesterday I had a challenging meeting with my team about a failed deployment.\n",
      "\n",
      "ğŸ“ Extracting episodes from message...\n",
      "ğŸ’¾ Storing 1 episode(s):\n",
      "\n",
      "   Episode 1:\n",
      "   â° [Timestamp: 2025-12-11 22:05:25]\n",
      "Yesterday, I had a challenging meeting with my team about a failed deployment. The team members involved were my colleagues, and the outcome of the meeting was a discussion on how to address the issues that led to the deployment failure.\n",
      "\n",
      "ğŸ” Retrieving relevant episodes from memory...\n",
      "âœ“ Found 2 relevant episode(s):\n",
      "\n",
      "   Retrieved Episode 1:\n",
      "   ğŸ“– [Timestamp: 2025-12-11 22:05:25]\n",
      "Yesterday, I had a challenging meeting with my team about a failed deployment. The team members involved were my colleagues, and the outcome of the meeting was a discussion on how to address the issues that led to the deployment failure.\n",
      "\n",
      "   Retrieved Episode 2:\n",
      "   ğŸ“– [Timestamp: 2025-12-11 22:05:18]\n",
      "Last month, I attended an AI conference in Berlin where I met amazing people working on LLMs. The event allowed me to network with professionals in the field, enhancing my understanding of language models and their applications.\n",
      "\n",
      "Turn 3: Agent Response\n",
      "<< That sounds like a tough situation to navigate. Addressing a failed deployment can be stressful, especially when it involves team dynamics. It's good that you had a meeting to discuss the issues. What were some of the key takeaways or solutions that came out of that discussion? It might be helpful to reflect on what you learned from the experience.\n",
      "\n",
      "ğŸ“š Episodes stored in memory: 2\n",
      "------------------------------------------------------------\n",
      "\n",
      "Turn 4: User Input\n",
      ">> How did my experiences shape my current situation?\n",
      "\n",
      "ğŸ“ Extracting episodes from message...\n",
      "âŠ˜ No episodes extracted from this message\n",
      "ğŸ” Retrieving relevant episodes from memory...\n",
      "âœ“ Found 2 relevant episode(s):\n",
      "\n",
      "   Retrieved Episode 1:\n",
      "   ğŸ“– [Timestamp: 2025-12-11 22:05:25]\n",
      "Yesterday, I had a challenging meeting with my team about a failed deployment. The team members involved were my colleagues, and the outcome of the meeting was a discussion on how to address the issues that led to the deployment failure.\n",
      "\n",
      "   Retrieved Episode 2:\n",
      "   ğŸ“– [Timestamp: 2025-12-11 22:05:18]\n",
      "Last month, I attended an AI conference in Berlin where I met amazing people working on LLMs. The event allowed me to network with professionals in the field, enhancing my understanding of language models and their applications.\n",
      "\n",
      "Turn 4: Agent Response\n",
      "<< Your recent experiences have likely had a significant impact on your current situation. Attending the AI conference in Berlin allowed you to network with professionals and gain insights into language models, which can enhance your problem-solving skills and knowledge base. This newfound understanding may help you approach challenges, like the failed deployment you discussed in your meeting, with a more informed perspective.\n",
      "\n",
      "The challenging meeting about the failed deployment might have also provided you with valuable lessons in teamwork and communication. By discussing the issues openly with your colleagues, you can identify the root causes and work towards better strategies for future deployments. This combination of learning from industry experts and reflecting on your team's experience can empower you to tackle similar challenges more effectively moving forward. How do you feel these experiences are influencing your approach to current projects?\n",
      "\n",
      "ğŸ“š Episodes stored in memory: 2\n",
      "------------------------------------------------------------\n",
      "\n",
      "âœ“ Multi-turn conversation completed\n",
      "âœ“ Total episodes stored in episodic memory: 2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Clear the episode store for a fresh demo\n",
    "    print(\"ğŸ—‘ï¸  Clearing previous episodes for a fresh start...\")\n",
    "    if len(episode_store.get()[\"ids\"]) > 0:\n",
    "        episode_store.delete(episode_store.get()[\"ids\"])\n",
    "        print(f\"âœ“ Cleared {len(episode_store.get()['ids'])} old episodes\\n\")\n",
    "    else:\n",
    "        print(\"âœ“ Store is empty\\n\")\n",
    "    \n",
    "    # Initialize conversation with episodic memory\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"episodes\": []\n",
    "    }\n",
    "    \n",
    "    # Multi-turn conversation with episodic events\n",
    "    conversation_turns = [\n",
    "        \"Last month I attended a AI conference in Berlin where I met amazing people working on LLMs.\",\n",
    "        \"Tell me about my recent experiences.\",\n",
    "        \"Yesterday I had a challenging meeting with my team about a failed deployment.\",\n",
    "        \"How did my experiences shape my current situation?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"LONG-TERM EPISODIC MEMORY DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    current_state = initial_state.copy()\n",
    "    \n",
    "    for i, user_input in enumerate(conversation_turns, 1):\n",
    "        print(f\"Turn {i}: User Input\")\n",
    "        print(f\">> {user_input}\")\n",
    "        print()\n",
    "        \n",
    "        # Add user message to state\n",
    "        current_state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        \n",
    "        # Run the agent\n",
    "        result = graph.invoke(current_state)\n",
    "        current_state = result\n",
    "        \n",
    "        # Extract and display agent response\n",
    "        last_message = current_state[\"messages\"][-1]\n",
    "        print(f\"Turn {i}: Agent Response\")\n",
    "        print(f\"<< {last_message.content}\")\n",
    "        print()\n",
    "        \n",
    "        # Show episodic memory size\n",
    "        stored_count = len(episode_store.get()[\"ids\"])\n",
    "        print(f\"ğŸ“š Episodes stored in memory: {stored_count}\")\n",
    "        print(\"-\" * 60)\n",
    "        print()\n",
    "    \n",
    "    print(\"âœ“ Multi-turn conversation completed\")\n",
    "    print(f\"âœ“ Total episodes stored in episodic memory: {len(episode_store.get()['ids'])}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error running conversation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ceddc",
   "metadata": {},
   "source": [
    "## Key Takeaways: Long-Term Episodic Memory Pattern\n",
    "\n",
    "### How it Works:\n",
    "1. **Extract**: Specific events and experiences are extracted from user messages\n",
    "2. **Timestamp**: Events are timestamped to preserve temporal context\n",
    "3. **Store**: Rich episode narratives are stored in the vector database\n",
    "4. **Retrieve**: Relevant past experiences are retrieved based on current context\n",
    "5. **Contextualize**: Episodes augment the agent's understanding of the user's journey\n",
    "\n",
    "### Characteristics:\n",
    "- âœ… Remembers specific events with full context\n",
    "- âœ… Preserves temporal information (when things happened)\n",
    "- âœ… Retrieves semantically similar experiences\n",
    "- âœ… Better than semantic memory for narrative understanding\n",
    "- âœ… Helps agent understand cause-and-effect relationships\n",
    "- âŒ More verbose than semantic memory (longer storage)\n",
    "- âŒ Requires event extraction logic\n",
    "\n",
    "### Differences from Semantic Memory:\n",
    "| Aspect | Semantic | Episodic |\n",
    "|--------|----------|----------|\n",
    "| **Content** | Facts and knowledge | Events and experiences |\n",
    "| **Temporal** | Timeless | Time-aware |\n",
    "| **Context** | What is known | What happened and when |\n",
    "| **Use case** | General knowledge | Personal history |\n",
    "\n",
    "### Common Use Cases:\n",
    "- Personal diary or journal assistant\n",
    "- Mentoring systems tracking student progress\n",
    "- Customer service with interaction history\n",
    "- Project management tracking milestones\n",
    "- Therapy or coaching with session notes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
